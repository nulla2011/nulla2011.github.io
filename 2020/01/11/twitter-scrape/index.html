<!DOCTYPE html><head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1"><meta name="viewport" content="width=device-width, initial-scale=1"><meta name="description" content="简单记录一下我爬取推文的过程"><meta name="author" content="nulla"><meta name="keywords" content="python,twitter,声优"><meta name="copyright" content="copyright.liscense_type"><title>简单记录一下我爬取推文的过程</title><!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
<!--[if lt IE 9]><script src="https://cdn.bootcss.com/html5shiv/3.7.3/html5shiv.min.js"></script><script src="https://cdn.bootcss.com/respond/1.4.2/respond.min.js"></script><![endif]--><link rel="icon" href="/compass/imgs/favicon.ico"><link rel="stylesheet" href="/compass/stylesheets/font-awesome.min.css"><script>var algoliaConfig = {"on":false}</script><link rel="stylesheet" href="/compass/stylesheets/screen.css"><meta name="generator" content="Hexo 6.2.0"></head><body><div id="body-inner-wrapper"><header id="page-header"><nav id="nav"><div id="site-name">nulla</div><i class="fa fa-bars fa-2x" id="nav-icon" aria-hidden="true"></i><div id="nav-expanded"><a class="nav-word-item" href="/">主页</a><a class="nav-word-item" href="/archives">归档</a><a class="nav-word-item" href="/tags">标签</a><a class="nav-word-item" href="/categories">分类</a><a class="nav-word-item" href="/about">关于</a></div><div id="nav-list"><ul><li><a class="nav-list-item" href="/">主页</a></li><li><a class="nav-list-item" href="/archives">归档</a></li><li><a class="nav-list-item" href="/tags">标签</a></li><li><a class="nav-list-item" href="/categories">分类</a></li><li><a class="nav-list-item" href="/about">关于</a></li></ul></div></nav><div id="banner-wrapper"><div id="banner-pagetype-dependent-info"><h1 id="post-title">简单记录一下我爬取推文的过程</h1><span id="post-description"><i class="fa fa-calendar" aria-hidden="true"></i> 2020-01-11</span><span id="word-count">全文共 2038 字</span><span id="time-count">需阅读时间约 7 分钟</span></div></div><a title="回到顶部"><i class="fa fa-arrow-up" id="to-Top" aria-hidden="true"></i></a><a title="点击关闭目录"><i class="fa fa-toggle-on" id="toggle-on-Toc" aria-hidden="true"></i></a><a title="点击展开目录"><i class="fa fa-toggle-off" id="toggle-off-Toc" aria-hidden="true"></i></a></header><aside id="toc-column"><div id="toc-column-inner-wrapper"><div id="post-toc"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9C%A8twitter%E5%BC%80%E5%8F%91%E8%80%85%E5%B9%B3%E5%8F%B0%E5%88%9B%E5%BB%BAapp"><span class="toc-text">在twitter开发者平台创建app</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#twarc%E7%9A%84%E4%BD%BF%E7%94%A8"><span class="toc-text">twarc的使用</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%88%AC%E5%8F%96%E5%85%B6%E4%BD%99%E6%8E%A8%E6%96%87"><span class="toc-text">爬取其余推文</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%8E%92%E5%BA%8F"><span class="toc-text">排序</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%8B%E8%BD%BD%E5%9B%BE%E7%89%87%E5%8F%8A%E8%A7%86%E9%A2%91"><span class="toc-text">下载图片及视频</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%8E%B7%E5%8F%96%E5%85%B3%E6%B3%A8%E8%80%85%E5%88%97%E8%A1%A8"><span class="toc-text">获取关注者列表</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%BD%AC%E7%A0%81"><span class="toc-text">转码</span></a></li></ol></div></div></aside><main id="main-content-column"><div id="main-content-wrapper"><div id="post-full-content"><p>日本时间2020年新年，夹在众多声优的<a target="_blank" rel="noopener" href="https://twitter.com/jullie_egg/status/1211665129890140160">结</a><a target="_blank" rel="noopener" href="https://twitter.com/reimatsuzaki/status/1211844474088771584">婚</a><a target="_blank" rel="noopener" href="https://ameblo.jp/clown-happy/entry-12563615812.html">ご</a><a target="_blank" rel="noopener" href="https://ameblo.jp/yh---blog/entry-12563720617.html">報</a><a target="_blank" rel="noopener" href="https://twitter.com/nojomiy/status/1212222134203777024">告</a>之间，白石晴香的ご報告就显得那么的，不和谐？但是，在当天三个声优宣布结婚，转天两个（而且还都是爱马仕声优）的情况下，看到她的ご報告还是会惊一下，然后再仔细一看，哦人事变动啊。</p>
<p>白石晴香的ご報告如下：</p>
<p><img src="https://gitcode.net/message2011/tttp/-/raw/master/shiraishi/t01d00967ea5e56c8e8.png"></p>
<p><a target="_blank" rel="noopener" href="https://twitter.com/shiraharu48/status/1212027679785938948">原地址点我</a></p>
<p>从原来的事务所ヒラタオフィス离开，变成free了。她之前的推特账号看样子是staff也参与管理，而且第一条就写着期间限定推特（难道预示了什么）。于是之前的推特号要在一周后销号。</p>
<p>可是问题来了，我一没看过小埋，二没看过Anne Happy，对她还不太了解，这可咋办？先想办法把她推文全爬下来吧。</p>
<span id="more"></span>

<h2 id="在twitter开发者平台创建app"><a href="#在twitter开发者平台创建app" class="headerlink" title="在twitter开发者平台创建app"></a>在twitter开发者平台创建app</h2><p>爬取推文的话，轮子还不少。但首先你得去twitter开发者平台（<a target="_blank" rel="noopener" href="https://developer.twitter.com/en/apps">https://developer.twitter.com/en/apps</a>） 申请个app，申请方法我就不说了，网上有。但是听说不好申请，我不知道怎么回事立刻就申请成功了。现在回想起来，没有app就无法完成后续的工作，能马上申请到app真是万幸。</p>
<h2 id="twarc的使用"><a href="#twarc的使用" class="headerlink" title="twarc的使用"></a>twarc的使用</h2><p>twarc，地址：<a target="_blank" rel="noopener" href="https://github.com/DocNow/twarc/">https://github.com/DocNow/twarc/</a> 是我首先找到的一个能够爬取推文的项目。使用方法也很简单，按照readme中所说，timeline参数即能获取一个账号时间线上的推文，而且包含转推。但是，之前别人抓取推文就说过，twitter api中的get statuses&#x2F;user_timeline对数量有限制，只能获取3200条（<a target="_blank" rel="noopener" href="https://developer.twitter.com/en/docs/tweets/timelines/api-reference/get-statuses-user_timeline">https://developer.twitter.com/en/docs/tweets/timelines/api-reference/get-statuses-user_timeline</a>） 。twarc里也写到了因为用的是官方api所以只能获取3200条，白石晴香的发推数根据返回的数据显示是4242条。剩下的就得想其他办法了</p>
<h2 id="爬取其余推文"><a href="#爬取其余推文" class="headerlink" title="爬取其余推文"></a>爬取其余推文</h2><p>之后又找了一个<a target="_blank" rel="noopener" href="https://github.com/bpb27/twitter_scraping">使用其他方法爬取推文的项目</a> 和<a target="_blank" rel="noopener" href="https://github.com/himan94/Extraction-of-multiple-tweets-greater-than-3200--from-twitter">改进版</a> 发现是使用的<a target="_blank" rel="noopener" href="https://chromedriver.chromium.org/">webdriver</a> 驱动浏览器显示推文并爬取的。试用了一下发现几个问题：</p>
<ol>
<li>白石晴香的推文此时已被保护，只有登录上自己的号才能爬取她的推文内容。解决方法是加上在抓取之前让webdriver控制浏览器输入账号密码并登录的代码。</li>
<li>登录后显示的是新版推特UI，无法抓取。目前想到的方法只有安装goodtwitter插件（<a target="_blank" rel="noopener" href="https://chrome.google.com/webstore/detail/goodtwitter/jbanhionoclikdjnjlcmefiofgjimgca">https://chrome.google.com/webstore/detail/goodtwitter/jbanhionoclikdjnjlcmefiofgjimgca</a>）。在开始抓取之前装上即可返回原来的ui并成功抓取。</li>
</ol>
<p>抓取的只是推文id，还需要根据id抓取内容，这时我又想到了前面的twarc，赶紧导入。</p>
<p>最后的代码如下：（不会排版Jupyter Notebook我就把python代码分段粘了）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: UTF-8 -*-</span></span><br><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.common.keys <span class="keyword">import</span> Keys</span><br><span class="line"><span class="keyword">from</span> selenium.common.exceptions <span class="keyword">import</span> NoSuchElementException, StaleElementReferenceException</span><br><span class="line"><span class="keyword">from</span> time <span class="keyword">import</span> sleep</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># edit these three variables</span></span><br><span class="line">user = <span class="string">&#x27;shiraishi_haruk&#x27;</span></span><br><span class="line">start = datetime.datetime(<span class="number">2017</span>, <span class="number">1</span>, <span class="number">14</span>)  <span class="comment"># year, month, day</span></span><br><span class="line">end = datetime.datetime(<span class="number">2017</span>, <span class="number">2</span>, <span class="number">3</span>)  <span class="comment"># year, month, day</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># only edit these if you&#x27;re having problems</span></span><br><span class="line">delay = <span class="number">3</span>  <span class="comment"># time to wait on each page load before reading the page</span></span><br><span class="line">driver = webdriver.Chrome()  <span class="comment"># options are Chrome() Firefox() Safari()</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># don&#x27;t mess with this stuff</span></span><br><span class="line">twitter_ids_filename = <span class="string">&#x27;all_ids.json&#x27;</span></span><br><span class="line">days = (end - start).days + <span class="number">1</span></span><br><span class="line">id_selector = <span class="string">&#x27;.time a.tweet-timestamp&#x27;</span></span><br><span class="line">tweet_selector = <span class="string">&#x27;li.js-stream-item&#x27;</span></span><br><span class="line">user = user.lower()</span><br><span class="line">ids = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">format_day</span>(<span class="params">date</span>):</span><br><span class="line">    day = <span class="string">&#x27;0&#x27;</span> + <span class="built_in">str</span>(date.day) <span class="keyword">if</span> <span class="built_in">len</span>(<span class="built_in">str</span>(date.day)) == <span class="number">1</span> <span class="keyword">else</span> <span class="built_in">str</span>(date.day)</span><br><span class="line">    month = <span class="string">&#x27;0&#x27;</span> + <span class="built_in">str</span>(date.month) <span class="keyword">if</span> <span class="built_in">len</span>(<span class="built_in">str</span>(date.month)) == <span class="number">1</span> <span class="keyword">else</span> <span class="built_in">str</span>(date.month)</span><br><span class="line">    year = <span class="built_in">str</span>(date.year)</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&#x27;-&#x27;</span>.join([year, month, day])</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">form_url</span>(<span class="params">since, until</span>):</span><br><span class="line">    p1 = <span class="string">&#x27;https://twitter.com/search?f=tweets&amp;vertical=default&amp;q=from%3A&#x27;</span></span><br><span class="line">    p2 =  user + <span class="string">&#x27;%20since%3A&#x27;</span> + since + <span class="string">&#x27;%20until%3A&#x27;</span> + until + <span class="string">&#x27;include%3Aretweets&amp;src=typd&#x27;</span></span><br><span class="line">    <span class="keyword">return</span> p1 + p2</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">increment_day</span>(<span class="params">date, i</span>):</span><br><span class="line">    <span class="keyword">return</span> date + datetime.timedelta(days=i)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">driver.get(<span class="string">&#x27;https://twitter.com/search?f=tweets&amp;vertical=default&amp;q=from%3Ashiraishi_haruk%20since%3A2016-03-15%20until%3A2016-03-16include%3Aretweets&amp;src=typd&#x27;</span>)</span><br><span class="line">driver.find_element_by_name(<span class="string">&quot;session[username_or_email]&quot;</span>).send_keys(<span class="string">&#x27;youremail&#x27;</span>)</span><br><span class="line">driver.find_element_by_name(<span class="string">&quot;session[password]&quot;</span>).send_keys(<span class="string">&#x27;yourpassword&#x27;</span>)</span><br><span class="line">driver.find_element_by_class_name(<span class="string">&quot;submit&quot;</span>).click()</span><br><span class="line">sleep(<span class="number">30</span>)</span><br><span class="line">    </span><br><span class="line"><span class="keyword">for</span> day <span class="keyword">in</span> <span class="built_in">range</span>(days):</span><br><span class="line">    d1 = format_day(increment_day(start, <span class="number">0</span>))</span><br><span class="line">    d2 = format_day(increment_day(start, <span class="number">1</span>))</span><br><span class="line">    url = form_url(d1, d2)</span><br><span class="line">    <span class="built_in">print</span>(url)</span><br><span class="line">    <span class="built_in">print</span>(d1)</span><br><span class="line">    driver.get(url)</span><br><span class="line">    </span><br><span class="line">    sleep(delay)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        found_tweets = driver.find_elements_by_css_selector(tweet_selector)</span><br><span class="line">        increment = <span class="number">10</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> <span class="built_in">len</span>(found_tweets) &gt;= increment:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;scrolling down to load more tweets&#x27;</span>)</span><br><span class="line">            driver.execute_script(<span class="string">&#x27;window.scrollTo(0, document.body.scrollHeight);&#x27;</span>)</span><br><span class="line">            sleep(delay)</span><br><span class="line">            found_tweets = driver.find_elements_by_css_selector(tweet_selector)</span><br><span class="line">            increment += <span class="number">10</span></span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;&#123;&#125; tweets found, &#123;&#125; total&#x27;</span>.<span class="built_in">format</span>(<span class="built_in">len</span>(found_tweets), <span class="built_in">len</span>(ids)))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> tweet <span class="keyword">in</span> found_tweets:</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                <span class="built_in">id</span> = tweet.find_element_by_css_selector(id_selector).get_attribute(<span class="string">&#x27;href&#x27;</span>).split(<span class="string">&#x27;/&#x27;</span>)[-<span class="number">1</span>]</span><br><span class="line">                ids.append(<span class="built_in">id</span>)</span><br><span class="line">            <span class="keyword">except</span> StaleElementReferenceException <span class="keyword">as</span> e:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&#x27;lost element reference&#x27;</span>, tweet)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">except</span> NoSuchElementException:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;no tweets on this day&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    start = increment_day(start, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(twitter_ids_filename) <span class="keyword">as</span> f:</span><br><span class="line">        all_ids = ids + json.load(f)</span><br><span class="line">        data_to_write = <span class="built_in">list</span>(<span class="built_in">set</span>(all_ids))</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;tweets found on this scrape: &#x27;</span>, <span class="built_in">len</span>(ids))</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;total tweet count: &#x27;</span>, <span class="built_in">len</span>(data_to_write))</span><br><span class="line"><span class="keyword">except</span> FileNotFoundError:</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(twitter_ids_filename, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        all_ids = ids</span><br><span class="line">        data_to_write = <span class="built_in">list</span>(<span class="built_in">set</span>(all_ids))</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;tweets found on this scrape: &#x27;</span>, <span class="built_in">len</span>(ids))</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;total tweet count: &#x27;</span>, <span class="built_in">len</span>(data_to_write))</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(twitter_ids_filename, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> outfile:</span><br><span class="line">    json.dump(data_to_write, outfile)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;all done here&#x27;</span>)</span><br><span class="line">driver.close()</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">tw = twarc.Twarc(CONSUMER_KEY, CONSUMER_SECRET, OAUTH_TOKEN, OAUTH_TOKEN_SECRET)</span><br><span class="line">f=<span class="built_in">open</span>(<span class="string">&quot;shiraishi_haruk_1701.json&quot;</span>,<span class="string">&quot;w&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> id_no <span class="keyword">in</span> ids:         <span class="comment"># store the ids in this list</span></span><br><span class="line">	<span class="keyword">try</span>:</span><br><span class="line">        tweet = tw.get(<span class="string">&#x27;https://api.twitter.com/1.1/statuses/show/%s.json&#x27;</span> % <span class="built_in">int</span>(id_no))</span><br><span class="line">        json.dump(tweet.json(),f)</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(e)</span><br><span class="line">        time.sleep(<span class="number">60</span> * <span class="number">15</span>)</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">    <span class="keyword">except</span> StopIteration:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">f.close()</span><br></pre></td></tr></table></figure>

<p>中间省略了导入模块以及初始化各种key还有string的内容</p>
<p><img src="https://gitcode.net/message2011/tttp/-/raw/master/shiraishi/t0145de27f6fc101ccd.png"></p>
<p>抓取成功</p>
<h2 id="排序"><a href="#排序" class="headerlink" title="排序"></a>排序</h2><p>等全部抓下来才发现顺序没排好，每天的发推排序都是时间倒序，而抓的时候是以天为单位时间正序抓到文件里的。于是上python排序，还挺好用</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line">lines=[]</span><br><span class="line">name=<span class="string">&#x27;shiraishi_haruk_1604_l&#x27;</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(name+<span class="string">&#x27;.json&#x27;</span>,<span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">	<span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">		line=f.readline()</span><br><span class="line">		<span class="keyword">if</span> <span class="keyword">not</span> line: <span class="keyword">break</span></span><br><span class="line">		line_json=json.loads(line)</span><br><span class="line">		lines.append(line_json)</span><br><span class="line"></span><br><span class="line">lines=<span class="built_in">sorted</span>(lines,key=<span class="keyword">lambda</span> k:k[<span class="string">&quot;id&quot;</span>],reverse=<span class="literal">True</span>)</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(name+<span class="string">&#x27;_sorted.json&#x27;</span>,<span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> fi:</span><br><span class="line">	<span class="keyword">for</span> item <span class="keyword">in</span> lines:</span><br><span class="line">		json.dump(item,fi)</span><br><span class="line">		fi.write(<span class="string">&quot;\n&quot;</span>)</span><br></pre></td></tr></table></figure>



<h2 id="下载图片及视频"><a href="#下载图片及视频" class="headerlink" title="下载图片及视频"></a>下载图片及视频</h2><p>扒图就很简单了，先使用twarc的工具（&#x2F;utils&#x2F;noretweets.py）对json文件去除转推和引用，再使用正则表达式搜索图片（格式为：”media_url_https”:”<a target="_blank" rel="noopener" href="https://pbs.twimg.com/media/%E5%8D%81%E4%BA%94%E4%BD%8D%E5%A4%A7%E5%B0%8F%E5%86%99%E5%AD%97%E6%AF%8D+%E6%95%B0%E5%AD%97+%E6%A8%AA%E7%BA%BF%E4%B8%8B%E5%88%92%E7%BA%BF%E7%BB%84%E5%90%88.jpg&quot;%EF%BC%89%EF%BC%8C%E6%8A%8Aurl%E5%85%A8%E7%B2%98%E8%BF%9Btxt%E6%96%87%E4%BB%B6%E7%94%A8aria2%E6%89%B9%E9%87%8F%E4%B8%8B%E8%BD%BD%E5%8D%B3%E5%8F%AF%E3%80%82">https://pbs.twimg.com/media/十五位大小写字母+数字+横线下划线组合.jpg&quot;），把url全粘进txt文件用aria2批量下载即可。</a></p>
<p>扒视频同理，搜索.mp4或.m3u8然后选码率最高的下载即可</p>
<h2 id="获取关注者列表"><a href="#获取关注者列表" class="headerlink" title="获取关注者列表"></a>获取关注者列表</h2><p>使用twarc followers命令即可。获取的都是账号id，你需要工具（<a target="_blank" rel="noopener" href="https://tweeterid.com/">tweeterid.com</a> 或 <a target="_blank" rel="noopener" href="http://gettwitterid.com/">gettwitterid.com</a>）来进行id和用户名的相互转换。这个号的关注数是0所以获取关注就不说了</p>
<h2 id="转码"><a href="#转码" class="headerlink" title="转码"></a>转码</h2><p>获取的推特文本都是被unicode编码过的无法读懂的字符串，如图</p>
<p><img src="https://gitcode.net/message2011/tttp/-/raw/master/shiraishi/t017b1e6f845163d1a0.png"></p>
<p>需要对其进行解码。首先考虑的是用python解，可是跑着跑着突然报错了。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">UnicodeEncodeError: &#x27;utf-8&#x27; codec can&#x27;t encode characters in position 31295-31296: surrogates not allowed</span><br></pre></td></tr></table></figure>

<p>经过对数据分段排查，发现竟然是一个小小的emoji的锅</p>
<p><img src="https://gitcode.net/message2011/tttp/-/raw/master/shiraishi/t01c55d777056959d5f.png"></p>
<p>这个emoji，在文件里的编码是\ud83d\udc40，但是在python中无法识别。搜索了一下让python支持的方法，发现要想支持，python得是UCS-2编译的，而现在一般都是UCS-4编译，于是放弃，转用JS。</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> fs = <span class="built_in">require</span>(<span class="string">&#x27;fs&#x27;</span>);</span><br><span class="line"> </span><br><span class="line"><span class="keyword">var</span> rs = fs.<span class="title function_">createReadStream</span>(<span class="string">&quot;./haruka1.json&quot;</span>),    data = <span class="string">&quot;&quot;</span>;</span><br><span class="line">rs.<span class="title function_">setEncoding</span>(<span class="string">&quot;utf8&quot;</span>);</span><br><span class="line">rs.<span class="title function_">on</span>(<span class="string">&quot;data&quot;</span>, <span class="keyword">function</span>(<span class="params">chunk</span>) &#123;</span><br><span class="line">	chunk = <span class="built_in">unescape</span>(chunk.<span class="title function_">replace</span>(<span class="regexp">/\\u/g</span>, <span class="string">&quot;%u&quot;</span>));</span><br><span class="line">	data += chunk;</span><br><span class="line">&#125;);</span><br><span class="line">rs.<span class="title function_">on</span>(<span class="string">&quot;end&quot;</span>, <span class="keyword">function</span>(<span class="params"></span>) &#123;</span><br><span class="line">	<span class="comment">//console.log(data);</span></span><br><span class="line">	fs.<span class="title function_">writeFile</span>(<span class="string">&#x27;./shiraishi_haruk_1_transcoded.json&#x27;</span>, data, <span class="keyword">function</span>(<span class="params">err</span>) &#123;</span><br><span class="line">   		<span class="keyword">if</span> (err) </span><br><span class="line">       		<span class="keyword">return</span> <span class="variable language_">console</span>.<span class="title function_">error</span>(err);</span><br><span class="line">	&#125;);</span><br><span class="line">&#125;);</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>（其实json格式化那里自动就转码了，方便阅读文件而已）</p>
<hr>
<p>下载地址和说明见下一篇</p>
</div><div id="post-tags-container"><i class="fa fa-tags"></i> <a class="post-tag" href="/tags/python/">#python</a>  <a class="post-tag" href="/tags/twitter/">#twitter</a>  <a class="post-tag" href="/tags/%E5%A3%B0%E4%BC%98/">#声优</a></div></div></main><div id="pagination-wrapper"><a id="page-prev" href="/2020/01/12/twitter-shiraishi-haruk/"><i class="fa fa-chevron-left"></i> 对推文数据文件使用方法的一些说明</a><a id="page-next" href="/2020/01/10/newblog/">博客改版 <i class="fa fa-chevron-right"></i></a></div><footer id="page-footer"><div id="footer-wrapper"><div id="blog-meta">&copy;2017-2023 By nulla | 主题 - <a id='theme-name' target="_blank" rel="noopener" href="https://github.com/huan555/lemon-lime"> Lemon-Lime</a> | 驱动 - <a id='theme-powered-by' href=http://hexo.io> Hexo</a></div><div id="viewed-record"><script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_page_pv"><i class="fa fa-eye" aria-hidden="true"></i> <span id="busuanzi_value_page_pv"></span></span></div><div id="copyright-wrapper"><i class="fa fa-cc" aria-hidden="true"></i><div id="copyright">除非有特别声明，本博客所有文章均采用 <a rel="license" href=http://creativecommons.org/licenses/by-nc-sa/4.0/>CC BY-NC-SA 4.0 协议</a>.</div></div><div id="contact-me"><div id="rss"><a href="/atom.xml" type="application/atom+xml" rel="alternate" target="_blank"><i class="fa fa-rss" aria-hidden="true"></i></a></div><span id="weibo"><a target="_blank" rel="noopener" href="https://weibo.com/nulla2011"><i class="fa fa-weibo" aria-hidden="true"></i></a></span><span id="twitter"><a target="_blank" rel="noopener" href="https://twitter.com/nulla2011"><i class="fa fa-twitter" aria-hidden="true"></i></a></span><span id="email"><a href="mailto:nulla@outlook.com"><i class="fa fa-envelope-o" aria-hidden="true"></i></a></span><span id="youtube"><a target="_blank" rel="noopener" href="https://www.youtube.com/channel/UC8oZtp8ay0Omfl7VYOqOJFw"><i class="fa fa-youtube-play" aria-hidden="true"></i></a></span><span id="telegram"><a target="_blank" rel="noopener" href="https://t.me/nulla2011"><i class="fa fa-telegram" aria-hidden="true"></i></a></span></div></div></footer><script src="/compass/js/blog.js"></script></div></body>