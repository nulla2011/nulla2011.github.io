<!DOCTYPE html><head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1"><meta name="viewport" content="width=device-width, initial-scale=1"><meta name="description" content="简单记录一下我爬取推文的过程"><meta name="author" content="nulla"><meta name="keywords" content="声优,twitter,python"><meta name="copyright" content="copyright.liscense_type"><title>简单记录一下我爬取推文的过程</title><!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
<!--[if lt IE 9]><script src="https://cdn.bootcss.com/html5shiv/3.7.3/html5shiv.min.js"></script><script src="https://cdn.bootcss.com/respond/1.4.2/respond.min.js"></script><![endif]--><link rel="icon"><link rel="stylesheet" href="/compass/stylesheets/font-awesome.min.css"><script>var algoliaConfig = {"on":false}</script><link rel="stylesheet" href="/compass/stylesheets/screen.css"><meta name="generator" content="Hexo 4.2.0"></head><body><div id="body-inner-wrapper"><header id="page-header"><nav id="nav"><div id="site-name">nulla</div><i class="fa fa-bars fa-2x" id="nav-icon" aria-hidden="true"></i><div id="nav-expanded"><a class="nav-word-item" href="/">主页</a><a class="nav-word-item" href="/archives">归档</a><a class="nav-word-item" href="/tags">标签</a><a class="nav-word-item" href="/categories">分类</a><a class="nav-word-item" href="/about">关于</a></div><div id="nav-list"><ul><li><a class="nav-list-item" href="/">主页</a></li><li><a class="nav-list-item" href="/archives">归档</a></li><li><a class="nav-list-item" href="/tags">标签</a></li><li><a class="nav-list-item" href="/categories">分类</a></li><li><a class="nav-list-item" href="/about">关于</a></li></ul></div></nav><div id="banner-wrapper"><div id="banner-pagetype-dependent-info"><h1 id="post-title">简单记录一下我爬取推文的过程</h1><span id="post-description"><i class="fa fa-calendar" aria-hidden="true"></i> 2020-01-11</span><span id="word-count">全文共 1939 字</span><span id="time-count">需阅读时间约 7 分钟</span></div></div><a title="回到顶部"><i class="fa fa-arrow-up" id="to-Top" aria-hidden="true"></i></a><a title="点击关闭目录"><i class="fa fa-toggle-on" id="toggle-on-Toc" aria-hidden="true"></i></a><a title="点击展开目录"><i class="fa fa-toggle-off" id="toggle-off-Toc" aria-hidden="true"></i></a></header><aside id="toc-column"><div id="toc-column-inner-wrapper"><div id="post-toc"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#在twitter开发者平台创建app"><span class="toc-text">在twitter开发者平台创建app</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#twarc的使用"><span class="toc-text">twarc的使用</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#爬取其余推文"><span class="toc-text">爬取其余推文</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#排序"><span class="toc-text">排序</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#下载图片及视频"><span class="toc-text">下载图片及视频</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#获取关注者列表"><span class="toc-text">获取关注者列表</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#转码"><span class="toc-text">转码</span></a></li></ol></div></div></aside><main id="main-content-column"><div id="main-content-wrapper"><div id="post-full-content"><p>日本时间2020年新年，夹在众多声优的<a href="https://twitter.com/jullie_egg/status/1211665129890140160" target="_blank" rel="noopener">结</a><a href="https://twitter.com/reimatsuzaki/status/1211844474088771584" target="_blank" rel="noopener">婚</a><a href="https://ameblo.jp/clown-happy/entry-12563615812.html" target="_blank" rel="noopener">ご</a><a href="https://ameblo.jp/yh---blog/entry-12563720617.html" target="_blank" rel="noopener">報</a><a href="https://twitter.com/nojomiy/status/1212222134203777024" target="_blank" rel="noopener">告</a>之间，白石晴香的ご報告就显得那么的，不和谐？但是，在当天三个声优宣布结婚，转天两个（而且还都是爱马仕声优）的情况下，看到她的ご報告还是会惊一下，然后再仔细一看，哦人事变动啊。</p>
<p>白石晴香的ご報告如下：</p>
<p><img src="https://p0.ssl.qhmsg.com/t01d00967ea5e56c8e8.png" alt=""></p>
<p><a href="https://twitter.com/shiraharu48/status/1212027679785938948" target="_blank" rel="noopener">原地址点我</a></p>
<p>从原来的事务所ヒラタオフィス离开，变成free了。她之前的推特账号看样子是staff也参与管理，而且第一条就写着期间限定推特（难道预示了什么）。于是之前的推特号要在一周后销号。</p>
<p>可是问题来了，我一没看过小埋，二没看过Anne Happy，对她还不太了解，这可咋办？先想办法把她推文全爬下来吧。</p>
<a id="more"></a>

<h2 id="在twitter开发者平台创建app"><a href="#在twitter开发者平台创建app" class="headerlink" title="在twitter开发者平台创建app"></a>在twitter开发者平台创建app</h2><p>爬取推文的话，轮子还不少。但首先你得去twitter开发者平台（<a href="https://developer.twitter.com/en/apps" target="_blank" rel="noopener">https://developer.twitter.com/en/apps</a>） 申请个app，申请方法我就不说了，网上有。但是听说不好申请，我不知道怎么回事立刻就申请成功了。现在回想起来，没有app就无法完成后续的工作，能马上申请到app真是万幸。</p>
<h2 id="twarc的使用"><a href="#twarc的使用" class="headerlink" title="twarc的使用"></a>twarc的使用</h2><p>twarc，地址：<a href="https://github.com/DocNow/twarc/" target="_blank" rel="noopener">https://github.com/DocNow/twarc/</a> 是我首先找到的一个能够爬取推文的项目。使用方法也很简单，按照readme中所说，timeline参数即能获取一个账号时间线上的推文，而且包含转推。但是，之前别人抓取推文就说过，twitter api中的get statuses/user_timeline对数量有限制，只能获取3200条（<a href="https://developer.twitter.com/en/docs/tweets/timelines/api-reference/get-statuses-user_timeline" target="_blank" rel="noopener">https://developer.twitter.com/en/docs/tweets/timelines/api-reference/get-statuses-user_timeline</a>） 。twarc里也写到了因为用的是官方api所以只能获取3200条，白石晴香的发推数根据返回的数据显示是4242条。剩下的就得想其他办法了</p>
<h2 id="爬取其余推文"><a href="#爬取其余推文" class="headerlink" title="爬取其余推文"></a>爬取其余推文</h2><p>之后又找了一个<a href="https://github.com/bpb27/twitter_scraping" target="_blank" rel="noopener">使用其他方法爬取推文的项目</a> 和<a href="https://github.com/himan94/Extraction-of-multiple-tweets-greater-than-3200--from-twitter" target="_blank" rel="noopener">改进版</a> 发现是使用的<a href="https://chromedriver.chromium.org/" target="_blank" rel="noopener">webdriver</a> 驱动浏览器显示推文并爬取的。试用了一下发现几个问题：</p>
<ol>
<li>白石晴香的推文此时已被保护，只有登录上自己的号才能爬取她的推文内容。解决方法是加上在抓取之前让webdriver控制浏览器输入账号密码并登录的代码。</li>
<li>登录后显示的是新版推特UI，无法抓取。目前想到的方法只有安装goodtwitter插件（<a href="https://chrome.google.com/webstore/detail/goodtwitter/jbanhionoclikdjnjlcmefiofgjimgca" target="_blank" rel="noopener">https://chrome.google.com/webstore/detail/goodtwitter/jbanhionoclikdjnjlcmefiofgjimgca</a>）。在开始抓取之前装上即可返回原来的ui并成功抓取。</li>
</ol>
<p>抓取的只是推文id，还需要根据id抓取内容，这时我又想到了前面的twarc，赶紧导入。</p>
<p>最后的代码如下：（不会排版Jupyter Notebook我就把python代码分段粘了）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: UTF-8 -*-</span></span><br><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.common.keys <span class="keyword">import</span> Keys</span><br><span class="line"><span class="keyword">from</span> selenium.common.exceptions <span class="keyword">import</span> NoSuchElementException, StaleElementReferenceException</span><br><span class="line"><span class="keyword">from</span> time <span class="keyword">import</span> sleep</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># edit these three variables</span></span><br><span class="line">user = <span class="string">'shiraishi_haruk'</span></span><br><span class="line">start = datetime.datetime(<span class="number">2017</span>, <span class="number">1</span>, <span class="number">14</span>)  <span class="comment"># year, month, day</span></span><br><span class="line">end = datetime.datetime(<span class="number">2017</span>, <span class="number">2</span>, <span class="number">3</span>)  <span class="comment"># year, month, day</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># only edit these if you're having problems</span></span><br><span class="line">delay = <span class="number">3</span>  <span class="comment"># time to wait on each page load before reading the page</span></span><br><span class="line">driver = webdriver.Chrome()  <span class="comment"># options are Chrome() Firefox() Safari()</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># don't mess with this stuff</span></span><br><span class="line">twitter_ids_filename = <span class="string">'all_ids.json'</span></span><br><span class="line">days = (end - start).days + <span class="number">1</span></span><br><span class="line">id_selector = <span class="string">'.time a.tweet-timestamp'</span></span><br><span class="line">tweet_selector = <span class="string">'li.js-stream-item'</span></span><br><span class="line">user = user.lower()</span><br><span class="line">ids = []</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">format_day</span><span class="params">(date)</span>:</span></span><br><span class="line">    day = <span class="string">'0'</span> + str(date.day) <span class="keyword">if</span> len(str(date.day)) == <span class="number">1</span> <span class="keyword">else</span> str(date.day)</span><br><span class="line">    month = <span class="string">'0'</span> + str(date.month) <span class="keyword">if</span> len(str(date.month)) == <span class="number">1</span> <span class="keyword">else</span> str(date.month)</span><br><span class="line">    year = str(date.year)</span><br><span class="line">    <span class="keyword">return</span> <span class="string">'-'</span>.join([year, month, day])</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">form_url</span><span class="params">(since, until)</span>:</span></span><br><span class="line">    p1 = <span class="string">'https://twitter.com/search?f=tweets&amp;vertical=default&amp;q=from%3A'</span></span><br><span class="line">    p2 =  user + <span class="string">'%20since%3A'</span> + since + <span class="string">'%20until%3A'</span> + until + <span class="string">'include%3Aretweets&amp;src=typd'</span></span><br><span class="line">    <span class="keyword">return</span> p1 + p2</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">increment_day</span><span class="params">(date, i)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> date + datetime.timedelta(days=i)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">driver.get(<span class="string">'https://twitter.com/search?f=tweets&amp;vertical=default&amp;q=from%3Ashiraishi_haruk%20since%3A2016-03-15%20until%3A2016-03-16include%3Aretweets&amp;src=typd'</span>)</span><br><span class="line">driver.find_element_by_name(<span class="string">"session[username_or_email]"</span>).send_keys(<span class="string">'youremail'</span>)</span><br><span class="line">driver.find_element_by_name(<span class="string">"session[password]"</span>).send_keys(<span class="string">'yourpassword'</span>)</span><br><span class="line">driver.find_element_by_class_name(<span class="string">"submit"</span>).click()</span><br><span class="line">sleep(<span class="number">30</span>)</span><br><span class="line">    </span><br><span class="line"><span class="keyword">for</span> day <span class="keyword">in</span> range(days):</span><br><span class="line">    d1 = format_day(increment_day(start, <span class="number">0</span>))</span><br><span class="line">    d2 = format_day(increment_day(start, <span class="number">1</span>))</span><br><span class="line">    url = form_url(d1, d2)</span><br><span class="line">    print(url)</span><br><span class="line">    print(d1)</span><br><span class="line">    driver.get(url)</span><br><span class="line">    </span><br><span class="line">    sleep(delay)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        found_tweets = driver.find_elements_by_css_selector(tweet_selector)</span><br><span class="line">        increment = <span class="number">10</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> len(found_tweets) &gt;= increment:</span><br><span class="line">            print(<span class="string">'scrolling down to load more tweets'</span>)</span><br><span class="line">            driver.execute_script(<span class="string">'window.scrollTo(0, document.body.scrollHeight);'</span>)</span><br><span class="line">            sleep(delay)</span><br><span class="line">            found_tweets = driver.find_elements_by_css_selector(tweet_selector)</span><br><span class="line">            increment += <span class="number">10</span></span><br><span class="line"></span><br><span class="line">        print(<span class="string">'&#123;&#125; tweets found, &#123;&#125; total'</span>.format(len(found_tweets), len(ids)))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> tweet <span class="keyword">in</span> found_tweets:</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                id = tweet.find_element_by_css_selector(id_selector).get_attribute(<span class="string">'href'</span>).split(<span class="string">'/'</span>)[<span class="number">-1</span>]</span><br><span class="line">                ids.append(id)</span><br><span class="line">            <span class="keyword">except</span> StaleElementReferenceException <span class="keyword">as</span> e:</span><br><span class="line">                print(<span class="string">'lost element reference'</span>, tweet)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">except</span> NoSuchElementException:</span><br><span class="line">        print(<span class="string">'no tweets on this day'</span>)</span><br><span class="line"></span><br><span class="line">    start = increment_day(start, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="keyword">with</span> open(twitter_ids_filename) <span class="keyword">as</span> f:</span><br><span class="line">        all_ids = ids + json.load(f)</span><br><span class="line">        data_to_write = list(set(all_ids))</span><br><span class="line">        print(<span class="string">'tweets found on this scrape: '</span>, len(ids))</span><br><span class="line">        print(<span class="string">'total tweet count: '</span>, len(data_to_write))</span><br><span class="line"><span class="keyword">except</span> FileNotFoundError:</span><br><span class="line">    <span class="keyword">with</span> open(twitter_ids_filename, <span class="string">'w'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        all_ids = ids</span><br><span class="line">        data_to_write = list(set(all_ids))</span><br><span class="line">        print(<span class="string">'tweets found on this scrape: '</span>, len(ids))</span><br><span class="line">        print(<span class="string">'total tweet count: '</span>, len(data_to_write))</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> open(twitter_ids_filename, <span class="string">'w'</span>) <span class="keyword">as</span> outfile:</span><br><span class="line">    json.dump(data_to_write, outfile)</span><br><span class="line"></span><br><span class="line">print(<span class="string">'all done here'</span>)</span><br><span class="line">driver.close()</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">tw = twarc.Twarc(CONSUMER_KEY, CONSUMER_SECRET, OAUTH_TOKEN, OAUTH_TOKEN_SECRET)</span><br><span class="line">f=open(<span class="string">"shiraishi_haruk_1701.json"</span>,<span class="string">"w"</span>)</span><br><span class="line"><span class="keyword">for</span> id_no <span class="keyword">in</span> ids:         <span class="comment"># store the ids in this list</span></span><br><span class="line">	<span class="keyword">try</span>:</span><br><span class="line">        tweet = tw.get(<span class="string">'https://api.twitter.com/1.1/statuses/show/%s.json'</span> % int(id_no))</span><br><span class="line">        json.dump(tweet.json(),f)</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        print(e)</span><br><span class="line">        time.sleep(<span class="number">60</span> * <span class="number">15</span>)</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">    <span class="keyword">except</span> StopIteration:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">f.close()</span><br></pre></td></tr></table></figure>

<p>中间省略了导入模块以及初始化各种key还有string的内容</p>
<p><img src="https://p0.ssl.qhmsg.com/t0145de27f6fc101ccd.png" alt=""></p>
<p>抓取成功</p>
<h2 id="排序"><a href="#排序" class="headerlink" title="排序"></a>排序</h2><p>等全部抓下来才发现顺序没排好，每天的发推排序都是时间倒序，而抓的时候是以天为单位时间正序抓到文件里的。于是上python排序，还挺好用</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line">lines=[]</span><br><span class="line">name=<span class="string">'shiraishi_haruk_1604_l'</span></span><br><span class="line"><span class="keyword">with</span> open(name+<span class="string">'.json'</span>,<span class="string">'r'</span>) <span class="keyword">as</span> f:</span><br><span class="line">	<span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">		line=f.readline()</span><br><span class="line">		<span class="keyword">if</span> <span class="keyword">not</span> line: <span class="keyword">break</span></span><br><span class="line">		line_json=json.loads(line)</span><br><span class="line">		lines.append(line_json)</span><br><span class="line"></span><br><span class="line">lines=sorted(lines,key=<span class="keyword">lambda</span> k:k[<span class="string">"id"</span>],reverse=<span class="literal">True</span>)</span><br><span class="line"><span class="keyword">with</span> open(name+<span class="string">'_sorted.json'</span>,<span class="string">'w'</span>) <span class="keyword">as</span> fi:</span><br><span class="line">	<span class="keyword">for</span> item <span class="keyword">in</span> lines:</span><br><span class="line">		json.dump(item,fi)</span><br><span class="line">		fi.write(<span class="string">"\n"</span>)</span><br></pre></td></tr></table></figure>



<h2 id="下载图片及视频"><a href="#下载图片及视频" class="headerlink" title="下载图片及视频"></a>下载图片及视频</h2><p>扒图就很简单了，先使用twarc的工具（/utils/noretweets.py）对json文件去除转推和引用，再使用正则表达式搜索图片（格式为：”media_url_https”:”<a href="https://pbs.twimg.com/media/十五位大小写字母+数字+横线下划线组合.jpg&quot;），把url全粘进txt文件用aria2批量下载即可。" target="_blank" rel="noopener">https://pbs.twimg.com/media/十五位大小写字母+数字+横线下划线组合.jpg&quot;），把url全粘进txt文件用aria2批量下载即可。</a></p>
<p>扒视频同理，搜索.mp4或.m3u8然后选码率最高的下载即可</p>
<h2 id="获取关注者列表"><a href="#获取关注者列表" class="headerlink" title="获取关注者列表"></a>获取关注者列表</h2><p>使用twarc followers命令即可。获取的都是账号id，你需要工具（<a href="https://tweeterid.com/" target="_blank" rel="noopener">tweeterid.com</a> 或 <a href="http://gettwitterid.com/" target="_blank" rel="noopener">gettwitterid.com</a>）来进行id和用户名的相互转换。这个号的关注数是0所以获取关注就不说了</p>
<h2 id="转码"><a href="#转码" class="headerlink" title="转码"></a>转码</h2><p>获取的推特文本都是被unicode编码过的无法读懂的字符串，如图</p>
<p><img src="https://p0.ssl.qhmsg.com/t017b1e6f845163d1a0.png" alt=""></p>
<p>需要对其进行解码。首先考虑的是用python解，可是跑着跑着突然报错了。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">UnicodeEncodeError: &#39;utf-8&#39; codec can&#39;t encode characters in position 31295-31296: surrogates not allowed</span><br></pre></td></tr></table></figure>

<p>经过对数据分段排查，发现竟然是一个小小的emoji的锅</p>
<p><img src="https://p0.ssl.qhmsg.com/t01c55d777056959d5f.png" alt=""></p>
<p>这个emoji，在文件里的编码是\ud83d\udc40，但是在python中无法识别。搜索了一下让python支持的方法，发现要想支持，python得是UCS-2编译的，而现在一般都是UCS-4编译，于是放弃，转用JS。</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> fs = <span class="built_in">require</span>(<span class="string">'fs'</span>);</span><br><span class="line"> </span><br><span class="line"><span class="keyword">var</span> rs = fs.createReadStream(<span class="string">"./haruka1.json"</span>),    data = <span class="string">""</span>;</span><br><span class="line">rs.setEncoding(<span class="string">"utf8"</span>);</span><br><span class="line">rs.on(<span class="string">"data"</span>, <span class="function"><span class="keyword">function</span>(<span class="params">chunk</span>) </span>&#123;</span><br><span class="line">	chunk = <span class="built_in">unescape</span>(chunk.replace(<span class="regexp">/\\u/g</span>, <span class="string">"%u"</span>));</span><br><span class="line">	data += chunk;</span><br><span class="line">&#125;);</span><br><span class="line">rs.on(<span class="string">"end"</span>, <span class="function"><span class="keyword">function</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">	<span class="comment">//console.log(data);</span></span><br><span class="line">	fs.writeFile(<span class="string">'./shiraishi_haruk_1_transcoded.json'</span>, data, <span class="function"><span class="keyword">function</span>(<span class="params">err</span>) </span>&#123;</span><br><span class="line">   		<span class="keyword">if</span> (err) </span><br><span class="line">       		<span class="keyword">return</span> <span class="built_in">console</span>.error(err);</span><br><span class="line">	&#125;)</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line"><span class="built_in">console</span>.log(<span class="string">"success"</span>);</span><br></pre></td></tr></table></figure>

<p>（其实json格式化那里自动就转码了，方便阅读文件而已）</p>
<hr>
<p>下载地址和说明见下一篇</p>
</div><div id="post-tags-container"><i class="fa fa-tags"></i> <a class="post-tag" href="/tags/%E5%A3%B0%E4%BC%98/">#声优</a>  <a class="post-tag" href="/tags/twitter/">#twitter</a>  <a class="post-tag" href="/tags/python/">#python</a></div></div></main><div id="pagination-wrapper"><a id="page-prev" href="/2020/01/12/twitter-shiraishi-haruk/"><i class="fa fa-chevron-left"></i> 对推文数据文件使用方法的一些说明</a><a id="page-next" href="/2020/01/10/newblog/">博客改版 <i class="fa fa-chevron-right"></i></a></div><footer id="page-footer"><div id="footer-wrapper"><div id="blog-meta">&copy;2017-2020 By nulla | 主题 - <a id='theme-name' href="https://github.com/huan555/lemon-lime" target="_blank" rel="noopener"> Lemon-Lime</a> | 驱动 - <a id='theme-powered-by' href=http://hexo.io> Hexo</a></div><div id="viewed-record"><script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_page_pv"><i class="fa fa-eye" aria-hidden="true"></i> <span id="busuanzi_value_page_pv"></span></span></div><div id="copyright-wrapper"><i class="fa fa-cc" aria-hidden="true"></i><div id="copyright">除非有特别声明，本博客所有文章均采用 <a rel="license" href=http://creativecommons.org/licenses/by-nc-sa/4.0/>CC BY-NC-SA 4.0 协议</a>.</div></div><div id="contact-me"><div id="rss"><a href="/atom.xml" type="application/atom+xml" rel="alternate" target="_blank"><i class="fa fa-rss" aria-hidden="true"></i></a></div><span id="weibo"><a href="https://weibo.com/nulla2011" target="_blank" rel="noopener"><i class="fa fa-weibo" aria-hidden="true"></i></a></span><span id="twitter"><a href="https://twitter.com/nulla2011" target="_blank" rel="noopener"><i class="fa fa-twitter" aria-hidden="true"></i></a></span><span id="email"><a href="mailto:nulla@outlook.com"><i class="fa fa-envelope-o" aria-hidden="true"></i></a></span><span id="youtube"><a href="https://www.youtube.com/channel/UC8oZtp8ay0Omfl7VYOqOJFw" target="_blank" rel="noopener"><i class="fa fa-youtube-play" aria-hidden="true"></i></a></span><span id="telegram"><a href="https://t.me/nulla2011" target="_blank" rel="noopener"><i class="fa fa-telegram" aria-hidden="true"></i></a></span></div></div></footer><script src="/compass/js/blog.js"></script></div></body>